{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "81eb46e6-469e-47b1-b910-c21a0ca9ddaf",
   "metadata": {},
   "source": [
    "### Uncomment and install the following  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ea2eba59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install transformers\n",
    "# !pip install torch torchvision torchaudio\n",
    "# !pip install accelerate==0.26.0\n",
    "# !pip install openai\n",
    "\n",
    "# !pip install -U langchain langchain-openai\n",
    "# !pip install pdf2image\n",
    "# !pip install psycopg2\n",
    "# !pip install protobuf\n",
    "# !pip install sentencepiece\n",
    "# !pip install tiktoken==0.1.1\n",
    "# !pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d4d69a18-8937-46cd-b48e-91d535a3636f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/suhwali/jupyter/pycrap/venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from typing import List, Dict, Tuple\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "import json\n",
    "import logging\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "# from poppler import Poppler\n",
    "from PIL import Image\n",
    "import base64\n",
    "from pdf2image import convert_from_path\n",
    "from langchain_openai import ChatOpenAI\n",
    "import tempfile\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2efc1588",
   "metadata": {},
   "source": [
    "**Input Your Own API keys. Note, Open API KEY is required**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8d18ad8-338e-4930-a2ab-6c4065e128c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['LANGCHAIN_TRACING_V2'] = ''\n",
    "os.environ['LANGCHAIN_ENDPOINT'] = ''\n",
    "os.environ['LANGCHAIN_API_KEY'] = ''\n",
    "os.environ[\"OPENAI_API_KEY\"] = ''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd3e3750-c199-4d01-83c6-a648ef31f7e4",
   "metadata": {},
   "source": [
    "**Automated Concept-to-Standard Mapping with NLI Models**\n",
    "This notebook demonstrates an approach to automatically map educational concepts to relevant Common Core Standards using advanced Natural Language Inference (NLI) techniques. The workflow is designed to process annotated algebra textbooks and evaluate their alignment with Common Core standards in a robust and automated manner.\n",
    "\n",
    "***Key Components:***\n",
    "\n",
    "1. Concept Extraction: OpenAI's Vision Model (GPT-4o) is utilized to extract key concepts from textbook chapters.\n",
    "2. Cluster Alignment: Extracted concepts are initially compared to broader Common Core clusters using the NLI model. Concepts meeting a threshold similarity are further analyzed.\n",
    "3. Standard Evaluation: For clusters that surpass the threshold, the standards within them are compared against the extracted concepts to identify the most relevant standards.\n",
    "4. Evaluation Against Ground Truth: The identified standards are compared to the textbook’s ground-truth annotations, enabling performance evaluation of the model.\n",
    "\n",
    "***Resources***\n",
    "\n",
    "* Link to the annotated textbook: https://flexbooks.ck12.org/cbook/ck-12-algebra-i-concepts/\n",
    "* PDF of the textbook could be found in Data folder\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3014d5f0",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7c84068d-d0d3-4ec2-8a24-f2b19f63bb31",
   "metadata": {},
   "source": [
    "**PDFProcessor Class**\n",
    "The PDFProcessor class handles the conversion of PDF documents into images and their optimization for further processing.\n",
    "\n",
    "***Key Attributes:***\n",
    "\n",
    "1. dpi:\n",
    "\n",
    " * The resolution for converting PDF pages to images. Default is 200 DPI.\n",
    " * Higher DPI ensures better image quality but increases processing time and memory usage.\n",
    "\n",
    "**logger:**\n",
    "\n",
    "2. A logger to record the processing progress and errors.\n",
    "\n",
    "***Key Methods:***\n",
    "\n",
    "1. pdf_to_images(pdf_path: str) -> List[str]:\n",
    "   * Converts each page of a PDF into a JPEG image.\n",
    "   * Optimizes the images and encodes them in Base64 format for easy transmission or embedding.\n",
    "   * Steps:\n",
    "       1. Uses the convert_from_path function to generate images from the PDF.\n",
    "       2. Each image is optimized using the optimize_image method.\n",
    "       3. Saves the optimized image to a temporary directory and encodes it to Base64 using the encode_image method.\n",
    "       4. Logs progress for each processed page.\n",
    "   * Returns a list of Base64-encoded strings representing the PDF pages.\n",
    "2. optimize_image(image: Image.Image) -> Image.Image:\n",
    "   * Resizes the image to fit within a maximum dimension (default: 2000 pixels) while maintaining aspect ratio.\n",
    "   * Uses the Lanczos resampling filter for high-quality resizing.\n",
    "3. encode_image(image_path: str) -> str:\n",
    "   * Converts an image file to a Base64 string, suitable for embedding or sharing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dc09ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class PDFProcessor:\n",
    "    def __init__(self, dpi: int = 200):\n",
    "        self.dpi = dpi\n",
    "        logging.basicConfig(level=logging.INFO)\n",
    "        self.logger = logging.getLogger(__name__)\n",
    "\n",
    "    def pdf_to_images(self, pdf_path: str) -> List[str]:\n",
    "        \"\"\"Convert PDF pages to base64-encoded images.\"\"\"\n",
    "        try:\n",
    "            self.logger.info(f\"Converting PDF: {pdf_path}\")\n",
    "            images = convert_from_path(\n",
    "                pdf_path,\n",
    "                dpi=self.dpi,\n",
    "                fmt='JPEG',\n",
    "                thread_count=4\n",
    "            )\n",
    "\n",
    "            base64_images = []\n",
    "\n",
    "            with tempfile.TemporaryDirectory() as temp_dir:\n",
    "                for i, image in enumerate(images):\n",
    "                    image = self.optimize_image(image)\n",
    "                    temp_path = os.path.join(temp_dir, f'page_{i}.jpg')\n",
    "                    image.save(temp_path, 'JPEG', quality=85)\n",
    "                    base64_str = self.encode_image(temp_path)\n",
    "                    base64_images.append(base64_str)\n",
    "                    self.logger.info(f\"Processed page {i+1}/{len(images)}\")\n",
    "\n",
    "            return base64_images\n",
    "\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error processing PDF: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "    def optimize_image(self, image: Image.Image) -> Image.Image:\n",
    "        \"\"\"Optimize image size while maintaining quality.\"\"\"\n",
    "        max_dimension = 2000\n",
    "        ratio = min(max_dimension / max(image.size[0], image.size[1]), 1.0)\n",
    "        new_size = tuple(int(dim * ratio) for dim in image.size)\n",
    "\n",
    "        if ratio < 1.0:\n",
    "            image = image.resize(new_size, Image.Resampling.LANCZOS)\n",
    "\n",
    "        return image\n",
    "\n",
    "    @staticmethod\n",
    "    def encode_image(image_path: str) -> str:\n",
    "        \"\"\"Convert image to base64 string.\"\"\"\n",
    "        with open(image_path, \"rb\") as image_file:\n",
    "            return base64.b64encode(image_file.read()).decode('utf-8')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87d11e32",
   "metadata": {},
   "source": [
    "**ConceptAnalyzer Class**\n",
    "The ConceptAnalyzer class uses OpenAI’s language models to extract key concepts from documents and process metadata.\n",
    "\n",
    "***Key Attributes:***\n",
    "\n",
    "1. pdf_processor:\n",
    "    * An instance of the PDFProcessor class to handle PDF-to-image conversion.\n",
    "2. model:\n",
    "    * The OpenAI language model (e.g., gpt-4o-mini) for analyzing the extracted images and metadata.\n",
    "3. logger:\n",
    "    * A logger to record progress and handle errors during concept analysis.\n",
    "    \n",
    "***Key Methods:***\n",
    "\n",
    "1. analyze_document(pdf_path: str, metadata: Dict = None) -> Dict:\n",
    "    * The main method to process a PDF document and extract key concepts.\n",
    "    * Steps:\n",
    "           1. Metadata Handling: Initializes metadata (e.g., grade, domain, file name) if not provided.\n",
    "           2. PDF Conversion: Uses PDFProcessor.pdf_to_images to convert the PDF into Base64-encoded images.\n",
    "           3. Concept Extraction: Calls _process_concepts to send the images and metadata to the OpenAI model for concept extraction.\n",
    "           4. Result Saving: Saves the analysis result as a JSON file in a results directory next to the PDF.\n",
    "    * Returns the analysis result as a dictionary.\n",
    "2. _process_concepts(base64_images: List[str], metadata: Dict) -> Dict:\n",
    "    * Prepares a request for the OpenAI model, including metadata and the Base64-encoded images.\n",
    "    * Sends the request to the model and parses the response into a structured JSON format.\n",
    "    * Handles possible errors in the response (e.g., invalid JSON) and attempts to clean and parse it.\n",
    "3. _get_output_path(pdf_path: str) -> str:\n",
    "    * Constructs a path for saving the analysis results. Results are saved as a JSON file in a subdirectory named results.\n",
    "4. get_analysis_result(pdf_path: str) -> Dict:\n",
    "    * Retrieves previously saved analysis results, if available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "724a9947",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class ConceptAnalyzer:\n",
    "    def __init__(self, openai_api_key: str, model_name: str = \"gpt-4o-mini\", dpi: int = 200):\n",
    "        self.pdf_processor = PDFProcessor(dpi=dpi)\n",
    "        self.model = ChatOpenAI(\n",
    "            model=model_name,\n",
    "            max_tokens=4096,\n",
    "            temperature=0,\n",
    "            openai_api_key=openai_api_key\n",
    "        )\n",
    "        logging.basicConfig(level=logging.INFO)\n",
    "        self.logger = logging.getLogger(__name__)\n",
    "\n",
    "    def analyze_document(self, pdf_path: str, metadata: Dict = None) -> Dict:\n",
    "        \"\"\"Analyze concepts in a PDF document.\"\"\"\n",
    "        try:\n",
    "            if metadata is None:\n",
    "                metadata = {\n",
    "                    'grade': 'unknown',\n",
    "                    'domain': 'unknown',\n",
    "                    'file_name': os.path.basename(pdf_path)\n",
    "                }\n",
    "\n",
    "            self.logger.info(\n",
    "                f\"Starting analysis for document: {metadata['file_name']}\")\n",
    "\n",
    "            # Convert PDF to images\n",
    "            base64_images = self.pdf_processor.pdf_to_images(pdf_path)\n",
    "\n",
    "            # Process concepts\n",
    "            concepts_result = self._process_concepts(base64_images, metadata)\n",
    "\n",
    "            # Save results\n",
    "            output_path = self._get_output_path(pdf_path)\n",
    "            os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "\n",
    "            with open(output_path, 'w', encoding='utf-8') as f:\n",
    "                json.dump(concepts_result, f, indent=2)\n",
    "\n",
    "            self.logger.info(f\"Analysis completed and saved to: {output_path}\")\n",
    "            return concepts_result\n",
    "\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error analyzing document: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "    def _process_concepts(self, base64_images: List[str], metadata: Dict) -> Dict:\n",
    "        \"\"\"Process document for concepts analysis.\"\"\"\n",
    "        content = [\n",
    "            {\n",
    "                \"type\": \"text\",\n",
    "                \"text\": f\"\"\"\n",
    "You are an advanced AI assistant tasked with extracting key math concepts from a document. The document was\n",
    "uploaded with the following metadata:\n",
    "1. **Grade level:** {metadata['grade']}\n",
    "2. **Domain/Module:** {metadata['domain']}\n",
    "3. **File name:** {metadata['file_name']}\n",
    "\n",
    "Your goals are:\n",
    "1. Identify the **concepts** covered in the document (e.g., algebra, calculus, geometry).\n",
    "2. For each concept, extract its name and provide a concise description based on the content of the document.\n",
    "3. Optionally infer the significance of the grade level, domain/module, or file name if it helps clarify the\n",
    "concepts or content.\n",
    "\n",
    "### Output Schema:\n",
    "{{\n",
    "\"concepts\": [\n",
    "  {{\n",
    "    \"name\": \"string (name of the concept)\",\n",
    "    \"description\": \"string (description of the concept)\"\n",
    "  }}\n",
    "]\n",
    "}}\n",
    "\n",
    "Note, make sure you return valid json format with no escape problems\"\"\"\n",
    "            }\n",
    "        ]\n",
    "\n",
    "        # Add images to content\n",
    "        for base64_image in base64_images:\n",
    "            content.append({\n",
    "                \"type\": \"image_url\",\n",
    "                \"image_url\": {\"url\": f\"data:image/jpeg;base64,{base64_image}\"}\n",
    "            })\n",
    "\n",
    "        # Get model response\n",
    "        message = [{\"role\": \"user\", \"content\": content}]\n",
    "        response = self.model.invoke(message)\n",
    "\n",
    "        # Parse JSON response\n",
    "        try:\n",
    "            # First attempt: direct JSON parsing\n",
    "            return json.loads(response.content)\n",
    "        except json.JSONDecodeError:\n",
    "            try:\n",
    "                # Second attempt: clean the response and try again\n",
    "                cleaned_content = response.content.strip()\n",
    "\n",
    "                # Remove any markdown code block indicators\n",
    "                cleaned_content = cleaned_content.replace(\n",
    "                    '```json', '').replace('```', '')\n",
    "\n",
    "                # Find the JSON object boundaries\n",
    "                start_idx = cleaned_content.find('{')\n",
    "                end_idx = cleaned_content.rfind('}') + 1\n",
    "\n",
    "                if start_idx != -1 and end_idx > start_idx:\n",
    "                    json_str = cleaned_content[start_idx:end_idx]\n",
    "\n",
    "                    # Replace escaped quotes and clean up common issues\n",
    "                    json_str = json_str.replace('\\\\\"', '\"')\n",
    "                    json_str = json_str.replace('\\\\n', ' ')\n",
    "                    json_str = json_str.replace('\\\\', '')\n",
    "\n",
    "                    # Attempt to parse the cleaned JSON\n",
    "                    return json.loads(json_str)\n",
    "\n",
    "                self.logger.error(\n",
    "                    f\"Could not find valid JSON in response: {cleaned_content}\")\n",
    "                raise ValueError(\"No valid JSON found in response\")\n",
    "            except Exception as e:\n",
    "                self.logger.error(\n",
    "                    f\"Error parsing response: {str(e)}\\nResponse content: {response.content}\")\n",
    "                # Return a structured error response\n",
    "                return {\n",
    "                    \"error\": \"Failed to parse response\",\n",
    "                    \"concepts\": [],\n",
    "                    \"raw_response\": response.content\n",
    "                }\n",
    "\n",
    "    def _get_output_path(self, pdf_path: str) -> str:\n",
    "        \"\"\"Generate path for analysis result file.\"\"\"\n",
    "        base_path = Path(pdf_path)\n",
    "        return str(base_path.parent/\"results\" / f\"{base_path.stem}_concepts.json\")\n",
    "\n",
    "    def get_analysis_result(self, pdf_path: str) -> Dict:\n",
    "        \"\"\"Retrieve analysis results from file.\"\"\"\n",
    "        output_path = self._get_output_path(pdf_path)\n",
    "        if os.path.exists(output_path):\n",
    "            with open(output_path, 'r', encoding='utf-8') as f:\n",
    "                return json.load(f)\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bac5038",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class NLIResult:\n",
    "    entailment: float\n",
    "    neutral: float\n",
    "    contradiction: float\n",
    "    text1: str\n",
    "    text2: str\n",
    "\n",
    "    @property\n",
    "    def max_score(self) -> float:\n",
    "        return self.entailment\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "930cf289-73f2-4f8e-bdd5-f95631d7c357",
   "metadata": {},
   "source": [
    "**NLIProcessor Class**\n",
    "The NLIProcessor class is a utility designed to leverage a pre-trained Natural Language Inference (NLI) model to evaluate the semantic relationship between two text inputs. It specifically helps map educational concepts to relevant clusters or standards within the context of Common Core alignment.\n",
    "\n",
    "***Key Attributes:***\n",
    "\n",
    "**model_name:**\n",
    "The name of the pre-trained NLI model used. By default, it uses \"ynie/xlnet-large-cased-snli_mnli_fever_anli_R1_R2_R3-nli\", a large, fine-tuned model for various NLI tasks.\n",
    "\n",
    "**max_length:**\n",
    "Specifies the maximum token length for inputs. Long texts are truncated to fit this limit.\n",
    "\n",
    "**threshold:**\n",
    "A configurable similarity threshold (default: 0.7). Only pairs exceeding this threshold are considered relevant.\n",
    "tokenizer and model:\n",
    "The tokenizer and model are initialized using Hugging Face's transformers library to process and infer relationships between input pairs.\n",
    "\n",
    "***device:***\n",
    "Automatically uses a GPU if available, otherwise falls back to CPU, ensuring optimal performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86b17df1-13bf-4664-9cbe-0602db71fbda",
   "metadata": {},
   "source": [
    "***Key Methods:***\n",
    "\n",
    "***process_pair***(premise: str, hypothesis: str) -> NLIResult:\n",
    "* Compares a single \"premise\" (e.g., a concept description) with a \"hypothesis\" (e.g., a cluster or standard).\n",
    "* Tokenizes the input pair, runs it through the NLI model, and calculates probabilities for three categories:\n",
    " * Entailment: How strongly the hypothesis follows from the premise.\n",
    " * Neutral: No strong relationship between the premise and hypothesis.\n",
    " * Contradiction: The hypothesis contradicts the premise. Outputs an NLIResult object containing these probabilities and the original texts.\n",
    "\n",
    "***process_concept_against_clusters***(concept_description: str, clusters: List[Cluster]) -> List[Tuple[Cluster, NLIResult]]:\n",
    "\n",
    "* Compares a concept description against a list of clusters.\n",
    "* For each cluster, it evaluates the semantic similarity (entailment score) between the concept and the cluster’s description (cluster.clustername).\n",
    "* Filters and sorts results based on the threshold and alignment strength.\n",
    "\n",
    "***process_concept_against_standards***(concept_description: str, standards: List[Standard]) -> List[Tuple[Standard, NLIResult]]:\n",
    "* Similar to process_concept_against_clusters, but compares the concept description against individual standards instead of clusters.\n",
    "* Evaluates the semantic alignment with each standard’s description (standard.standarddescription)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8b676c3d-485b-4ed8-a787-9ea7b16e0c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import XLNetTokenizer\n",
    "class NLIProcessor:\n",
    "\n",
    "\n",
    "    def __init__(self, model_name: str = \"ynie/xlnet-large-cased-snli_mnli_fever_anli_R1_R2_R3-nli\"):\n",
    "        self.model_name = model_name\n",
    "        self.max_length = 256\n",
    "        self.threshold = 0.7  # Configurable threshold for relationship strength\n",
    "\n",
    "        # Initialize logger\n",
    "        self.logger = logging.getLogger(__name__)\n",
    "\n",
    "        # Load model and tokenizer\n",
    "        self.logger.info(f\"Loading NLI model: {model_name}\")\n",
    "        self.tokenizer = XLNetTokenizer.from_pretrained(\n",
    "            model_name,\n",
    "            use_fast=True,\n",
    "            model_max_length=256\n",
    "        )\n",
    "        self.model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "        # Move model to GPU if available\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        self.model.to(self.device)\n",
    "        self.model.eval()  # Set to evaluation mode\n",
    "\n",
    "    def process_pair(self, premise: str, hypothesis: str) -> NLIResult:\n",
    "        \"\"\"Process a single premise-hypothesis pair.\"\"\"\n",
    "        try:\n",
    "            # Tokenize\n",
    "            inputs = self.tokenizer.encode_plus(\n",
    "                premise,\n",
    "                hypothesis,\n",
    "                max_length=self.max_length,\n",
    "                return_token_type_ids=True,\n",
    "                truncation=True,\n",
    "                padding='max_length',\n",
    "                return_tensors='pt'\n",
    "            )\n",
    "\n",
    "            # Move inputs to same device as model\n",
    "            inputs = {k: v.to(self.device) for k, v in inputs.items()}\n",
    "\n",
    "            # Get predictions\n",
    "            with torch.no_grad():\n",
    "                outputs = self.model(**inputs)\n",
    "                probabilities = torch.softmax(outputs.logits, dim=1)[0]\n",
    "\n",
    "            # Create result object\n",
    "            result = NLIResult(\n",
    "                entailment=probabilities[0].item(),\n",
    "                neutral=probabilities[1].item(),\n",
    "                contradiction=probabilities[2].item(),\n",
    "\n",
    "                text1=premise,\n",
    "                text2=hypothesis\n",
    "            )\n",
    "\n",
    "            return result\n",
    "\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error processing NLI pair: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "    def process_concept_against_clusters(self,\n",
    "                                      concept_description: str,\n",
    "                                      clusters: List['Cluster']) -> List[Tuple['Cluster', NLIResult]]:\n",
    "        \"\"\"Process a concept description against multiple clusters.\"\"\"\n",
    "        results = []\n",
    "        for cluster in clusters:\n",
    "            result = self.process_pair(concept_description, cluster.clustername)\n",
    "            if result.max_score >= self.threshold:\n",
    "                # print(result)\n",
    "                results.append((cluster, result))\n",
    "\n",
    "        return sorted(results, key=lambda x: x[1].max_score, reverse=True)\n",
    "\n",
    "    def process_concept_against_standards(self,\n",
    "                                       concept_description: str,\n",
    "                                       standards: List['Standard']) -> List[Tuple['Standard', NLIResult]]:\n",
    "\n",
    "        \"\"\"Process a concept description against multiple standards.\"\"\"\n",
    "        results = []\n",
    "        for standard in standards:\n",
    "            result = self.process_pair(concept_description, standard.standarddescription)\n",
    "            print(result)\n",
    "            if result.max_score >= self.threshold:\n",
    "                results.append((standard, result))\n",
    "\n",
    "        return sorted(results, key=lambda x: x[1].max_score, reverse=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "704fdb7c-0f7b-492b-a4be-02e47d70d254",
   "metadata": {},
   "source": [
    "**DataProcessor Class**  \n",
    "The DataProcessor class manages and verifies PDF files required for processing, ensuring all necessary files are present and providing metadata about them.\n",
    "\n",
    "***Key Attributes:***\n",
    "\n",
    "1. `base_dir`:\n",
    "    * The base directory containing PDF files. Default: `\"Data\"`.\n",
    "\n",
    "***Key Methods:***\n",
    "\n",
    "1. `get_chapter_files() -> List[Path]`:\n",
    "    * Retrieves all chapter files matching the pattern `\"chapter *.pdf\"`.\n",
    "    * Sorts the files numerically by chapter number.\n",
    "\n",
    "2. `get_test_file() -> Path`:\n",
    "    * Retrieves the test file (`test_file.pdf`) from the base directory.\n",
    "    * Raises a `FileNotFoundError` if the file does not exist.\n",
    "\n",
    "3. `verify_files() -> Tuple[bool, str]`:\n",
    "    * Ensures all chapters (1–12) and the test file are present.\n",
    "    * Returns:\n",
    "        - `True, \"All files verified successfully\"` if all files are valid.\n",
    "        - `False, \"Missing chapters: [...]\"` if any chapters are missing.\n",
    "\n",
    "4. `get_file_info() -> Dict`:\n",
    "    * Returns metadata for all relevant files:\n",
    "        - Test file: Path, size, last modified timestamp.\n",
    "        - Chapters: Number, path, size, and last modified timestamp for each file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "31ffa880-b7d0-44bb-97fa-f796d60ed9cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Tuple\n",
    "\n",
    "class DataProcessor:\n",
    "    def __init__(self, base_dir: str = \"vision_model_results/\"):\n",
    "        \"\"\"\n",
    "        Initialize the DataProcessor with the base directory path.\n",
    "\n",
    "        Args:\n",
    "            base_dir (str): Base directory containing the PDF files\n",
    "        \"\"\"\n",
    "        # self.base_dir = Path(base_dir)\n",
    "        self.base_dir = Path('Data')\n",
    "\n",
    "    def get_chapter_files(self) -> List[Path]:\n",
    "        \"\"\"Get all chapter PDF files sorted numerically.\"\"\"\n",
    "        chapter_files = [f for f in self.base_dir.glob(\"chapter *.pdf\")]\n",
    "        # Sort chapters numerically (1, 2, 3... 10, 11, 12 instead of 1, 10, 11...)\n",
    "        return sorted(chapter_files, key=lambda x: int(x.stem.split()[1]))\n",
    "\n",
    "    def get_test_file(self) -> Path:\n",
    "        \"\"\"Get the test file path.\"\"\"\n",
    "        test_file = self.base_dir / \"test_file.pdf\"\n",
    "        if not test_file.exists():\n",
    "            raise FileNotFoundError(f\"Test file not found in {self.base_dir}\")\n",
    "        return test_file\n",
    "\n",
    "    def verify_files(self) -> Tuple[bool, str]:\n",
    "        \"\"\"\n",
    "        Verify that all necessary files exist and are accessible.\n",
    "\n",
    "        Returns:\n",
    "            Tuple[bool, str]: (success status, message)\n",
    "        \"\"\"\n",
    "        try:\n",
    "            chapter_files = self.get_chapter_files()\n",
    "            test_file = self.get_test_file()\n",
    "\n",
    "            # Check if we have all chapters (1-12)\n",
    "            chapter_numbers = [int(f.stem.split()[1]) for f in chapter_files]\n",
    "            expected_chapters = set(range(1, 13))  # 1 to 12\n",
    "            missing_chapters = expected_chapters - set(chapter_numbers)\n",
    "\n",
    "            if missing_chapters:\n",
    "                return False, f\"Missing chapters: {sorted(missing_chapters)}\"\n",
    "\n",
    "            return True, \"All files verified successfully\"\n",
    "\n",
    "        except Exception as e:\n",
    "            return False, f\"Verification failed: {str(e)}\"\n",
    "\n",
    "    def get_file_info(self) -> Dict:\n",
    "        \"\"\"\n",
    "        Get information about all PDF files in the directory.\n",
    "\n",
    "        Returns:\n",
    "            Dict: Dictionary containing file information\n",
    "        \"\"\"\n",
    "        chapter_files = self.get_chapter_files()\n",
    "        test_file = self.get_test_file()\n",
    "\n",
    "        return {\n",
    "            \"test_file\": {\n",
    "                \"path\": str(test_file),\n",
    "                \"size\": test_file.stat().st_size,\n",
    "                \"last_modified\": test_file.stat().st_mtime\n",
    "            },\n",
    "            \"chapters\": [\n",
    "                {\n",
    "                    \"number\": int(f.stem.split()[1]),\n",
    "                    \"path\": str(f),\n",
    "                    \"size\": f.stat().st_size,\n",
    "                    \"last_modified\": f.stat().st_mtime\n",
    "                }\n",
    "                for f in chapter_files\n",
    "            ]\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72271ea3-a2e6-4820-a48b-065fb1c9911c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status: True\n",
      "Message: All files verified successfully\n",
      "Test file: Data/test_file.pdf\n",
      "\n",
      "Chapter files:\n",
      "- Data/chapter 1.pdf\n",
      "- Data/chapter 2.pdf\n",
      "- Data/chapter 3.pdf\n",
      "- Data/chapter 4.pdf\n",
      "- Data/chapter 5.pdf\n",
      "- Data/chapter 6.pdf\n",
      "- Data/chapter 7.pdf\n",
      "- Data/chapter 8.pdf\n",
      "- Data/chapter 9.pdf\n",
      "- Data/chapter 10.pdf\n",
      "- Data/chapter 11.pdf\n",
      "- Data/chapter 12.pdf\n",
      "\n",
      "File information:\n",
      "Test file path: Data/test_file.pdf\n",
      "Number of chapters: 12\n"
     ]
    }
   ],
   "source": [
    "# Initialize the processor\n",
    "processor = DataProcessor()\n",
    "\n",
    "# Verify all files exist\n",
    "status, message = processor.verify_files()\n",
    "print(f\"Status: {status}\")\n",
    "print(f\"Message: {message}\")\n",
    "\n",
    "\n",
    "\n",
    "# Get all chapter files\n",
    "chapter_files = processor.get_chapter_files()\n",
    "print(\"\\nChapter files:\")\n",
    "for chapter in chapter_files:\n",
    "    print(f\"- {chapter}\")\n",
    "\n",
    "# Get detailed file information\n",
    "file_info = processor.get_file_info()\n",
    "print(\"\\nFile information:\")\n",
    "print(f\"Chapter path: {file_info['test_file']['path']}\")\n",
    "print(f\"Number of chapters: {len(file_info['chapters'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7677ead8",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f992b98c",
   "metadata": {},
   "source": [
    "### **StandardsComparator Class**\n",
    "\n",
    "The `StandardsComparator` class facilitates mapping educational concepts to clusters and standards using a Natural Language Inference (NLI) model and database queries. It supports comparisons against ground truth for performance evaluation.\n",
    "\n",
    "---\n",
    "\n",
    "#### **Key Attributes:**\n",
    "\n",
    "1. `nli`:\n",
    "   * An instance of an NLI processor for semantic comparison between concepts, clusters, and standards.\n",
    "   \n",
    "2. `query_executor`:\n",
    "   * A utility to execute SQL queries for retrieving data from the database.\n",
    "\n",
    "3. `threshold`:\n",
    "   * The minimum similarity score for a concept-cluster or concept-standard match (default: `0.7`).\n",
    "\n",
    "4. `logger`:\n",
    "   * A logger to track progress and handle errors during processing.\n",
    "\n",
    "---\n",
    "\n",
    "#### **Key Methods:**\n",
    "\n",
    "1. **`get_domains_for_grade(grade_id: int) -> List[Domain]`**:\n",
    "   * Retrieves all domains associated with a specific grade from the database.\n",
    "   * **Returns:** A list of `Domain` objects.\n",
    "\n",
    "2. **`get_clusters_for_domain(domain_id: int) -> List[Cluster]`**:\n",
    "   * Fetches all clusters for a given domain.\n",
    "   * **Returns:** A list of `Cluster` objects.\n",
    "\n",
    "3. **`get_standards_for_cluster(cluster_id: int) -> List[Standard]`**:\n",
    "   * Retrieves all standards for a specific cluster.\n",
    "   * **Returns:** A list of `Standard` objects.\n",
    "\n",
    "4. **`match_concepts_to_clusters(concepts: List[Dict], clusters: List[Cluster]) -> List[Tuple[Dict, Cluster, float]]`**:\n",
    "   * Matches extracted concepts to clusters using NLI.\n",
    "   * **Steps:**\n",
    "       - Compares each concept (name + description) to cluster names.\n",
    "       - Retains matches with a similarity score above the threshold.\n",
    "       - Sorts results by score in descending order.\n",
    "   * **Returns:** A list of (concept, cluster, score) tuples.\n",
    "\n",
    "5. **`match_concepts_to_standards(concepts: List[Dict], standards: List[Standard]) -> List[Tuple[Dict, Standard, float]]`**:\n",
    "   * Matches extracted concepts to standards using NLI.\n",
    "   * **Steps:** Similar to `match_concepts_to_clusters`, but matches against standards' descriptions.\n",
    "   * **Returns:** A list of (concept, standard, score) tuples.\n",
    "\n",
    "6. **`compare_to_ground_truth(matched_standards: List[Tuple[Dict, Standard, float]], ground_truth_standards: List[int]) -> Dict`**:\n",
    "   * Compares matched standards to a ground truth set of standard IDs.\n",
    "   * **Metrics:**\n",
    "       - Precision: Proportion of correctly matched standards out of all matches.\n",
    "       - Recall: Proportion of ground truth standards correctly identified.\n",
    "       - F1 Score: Harmonic mean of precision and recall.\n",
    "   * **Returns:** A dictionary with metrics (`precision`, `recall`, `f1`) and counts (`true_positives`, `false_positives`, `false_negatives`).\n",
    "\n",
    "---\n",
    "\n",
    "#### **Workflow Summary:**\n",
    "1. Retrieve domains, clusters, and standards for a specific grade using database queries.\n",
    "2. Match extracted concepts to clusters and standards using semantic similarity (NLI).\n",
    "3. Filter results by threshold and sort by relevance.\n",
    "4. Evaluate performance against annotated ground truth standards using precision, recall, and F1 score.\n",
    "\n",
    "This class integrates data querying, semantic analysis, and evaluation, making it a comprehensive tool for educational concept mapping.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "856bceb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Update the StandardsComparator methods to use the new query executor\n",
    "\n",
    "\n",
    "import logging\n",
    "from typing import List, Dict, Tuple\n",
    "import pandas as pd\n",
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class Standard:\n",
    "    standardid: int\n",
    "    standardcode: str\n",
    "    standarddescription: str\n",
    "    clusterid: int\n",
    "    stadid: int\n",
    "\n",
    "@dataclass\n",
    "class Cluster:\n",
    "    clusterid: int\n",
    "    clustername: str\n",
    "    clustertype: str\n",
    "    domainid: int\n",
    "\n",
    "@dataclass\n",
    "class Domain:\n",
    "    domainid: int\n",
    "    domainname: str\n",
    "    domain_abb: str\n",
    "    gradeid: int\n",
    "\n",
    "class StandardsComparator:\n",
    "\n",
    "    def __init__(self, nli_processor, query_executor, threshold: float = 0.7 ):\n",
    "        \"\"\"\n",
    "        Initialize the standards comparator.\n",
    "        \n",
    "        Args:\n",
    "            nli_processor: NLI model processor instance\n",
    "            threshold: Threshold for relationship strength\n",
    "        \"\"\"\n",
    "        self.nli = nli_processor\n",
    "        self.threshold = threshold\n",
    "        self.query_executor = query_executor\n",
    "        self.logger = logging.getLogger(__name__)\n",
    "    \n",
    "    def get_domains_for_grade(self, grade_id: int) -> List[Domain]:\n",
    "        \"\"\"Get all domains for a given grade\"\"\"\n",
    "        query = \"\"\"\n",
    "        SELECT domainid, gradeid, domain_abb, domainname\n",
    "        FROM domains\n",
    "        where gradeid = %s\n",
    "        \"\"\"\n",
    "        \n",
    "        try:\n",
    "            results = self.query_executor.execute_query(query, (grade_id,))\n",
    "            return [Domain(\n",
    "                domainid=row[0],\n",
    "                domainname=row[1],\n",
    "                domain_abb=row[2],\n",
    "                gradeid=row[3]\n",
    "            ) for row in results]\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error fetching clusters: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def get_clusters_for_domain(self, domain_id: int) -> List[Cluster]:\n",
    "        \"\"\"Get all clusters for a given domain.\"\"\"\n",
    "        query = \"\"\"\n",
    "            SELECT clusterid, clustername, clustertype, domainid\n",
    "            FROM clusters\n",
    "            WHERE domainid = %s\n",
    "        \"\"\"\n",
    "        try:\n",
    "            results = self.query_executor.execute_query(query, (domain_id,))\n",
    "            return [Cluster(\n",
    "                clusterid=row[0],\n",
    "                clustername=row[1],\n",
    "                clustertype=row[2],\n",
    "                domainid=row[3]\n",
    "            ) for row in results]\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error fetching clusters: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "\n",
    "    def get_standards_for_cluster(self, cluster_id: int) -> List[Standard]:\n",
    "        \"\"\"Get all standards for a given cluster.\"\"\"\n",
    "        query = \"\"\"\n",
    "            SELECT standardid, standardcode, standarddescription, clusterid, stadid\n",
    "            FROM standards\n",
    "            WHERE clusterid = %s\n",
    "        \"\"\"\n",
    "        \n",
    "        try:\n",
    "            results = self.query_executor.execute_query(query, (cluster_id,))\n",
    "            return [Standard(\n",
    "                standardid=row[0],\n",
    "                standardcode=row[1],\n",
    "                standarddescription=row[2],\n",
    "                clusterid=row[3],\n",
    "                stadid=row[4]\n",
    "            ) for row in results]\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error fetching standards: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "    def match_concepts_to_clusters(\n",
    "        self,\n",
    "        concepts: List[Dict],\n",
    "        clusters: List[Cluster]\n",
    "    ) -> List[Tuple[Dict, Cluster, float]]:\n",
    "        \"\"\"\n",
    "        Match extracted concepts to clusters using NLI.\n",
    "        \n",
    "        Args:\n",
    "            concepts: List of concept dictionaries with 'name' and 'description'\n",
    "            clusters: List of Cluster objects\n",
    "            \n",
    "        Returns:\n",
    "            List of (concept, cluster, score) tuples above threshold\n",
    "        \"\"\"\n",
    "        matches = []\n",
    "        \n",
    "        for concept in concepts:\n",
    "            concept_text = f\"{concept['name']}: {concept['description']}\"\n",
    "            \n",
    "            for cluster in clusters:\n",
    "                result = self.nli.process_pair(concept_text, cluster.clustername)\n",
    "                \n",
    "                if result.max_score >= self.threshold:\n",
    "                    matches.append((concept, cluster, result.max_score))\n",
    "        \n",
    "        return sorted(matches, key=lambda x: x[2], reverse=True)\n",
    "\n",
    "    def match_concepts_to_standards(\n",
    "        self,\n",
    "        concepts: List[Dict],\n",
    "        standards: List[Standard]\n",
    "    ) -> List[Tuple[Dict, Standard, float]]:\n",
    "        \"\"\"\n",
    "        Match extracted concepts to standards using NLI.\n",
    "        \n",
    "        Args:\n",
    "            concepts: List of concept dictionaries\n",
    "            standards: List of Standard objects\n",
    "            \n",
    "        Returns:\n",
    "            List of (concept, standard, score) tuples above threshold\n",
    "        \"\"\"\n",
    "        matches = []\n",
    "        \n",
    "        for concept in concepts:\n",
    "            concept_text = f\"{concept['name']}: {concept['description']}\"\n",
    "            \n",
    "            for standard in standards:\n",
    "                result = self.nli.process_pair(concept_text, standard.standarddescription)\n",
    "                \n",
    "                if result.max_score >= self.threshold:\n",
    "                    matches.append((concept, standard, result.max_score))\n",
    "        \n",
    "        return sorted(matches, key=lambda x: x[2], reverse=True)\n",
    "\n",
    "    def compare_to_ground_truth(\n",
    "        self,\n",
    "        matched_standards: List[Tuple[Dict, Standard, float]],\n",
    "        ground_truth_standards: List[int]\n",
    "    ) -> Dict:\n",
    "        \"\"\"\n",
    "        Compare matched standards to ground truth standards.\n",
    "        \n",
    "        Args:\n",
    "            matched_standards: List of (concept, standard, score) tuples\n",
    "            ground_truth_standards: List of correct standard IDs\n",
    "            \n",
    "        Returns:\n",
    "            Dictionary with precision, recall, and F1 metrics\n",
    "        \"\"\"\n",
    "        matched_ids = set(standard.standardid for _, standard, _ in matched_standards)\n",
    "        ground_truth_ids = set(ground_truth_standards)\n",
    "        \n",
    "        true_positives = len(matched_ids.intersection(ground_truth_ids))\n",
    "        false_positives = len(matched_ids - ground_truth_ids)\n",
    "        false_negatives = len(ground_truth_ids - matched_ids)\n",
    "        \n",
    "        precision = true_positives / (true_positives + false_positives) if (true_positives + false_positives) > 0 else 0\n",
    "        recall = true_positives / (true_positives + false_negatives) if (true_positives + false_negatives) > 0 else 0\n",
    "        f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "        \n",
    "        return {\n",
    "            'precision': precision,\n",
    "            'recall': recall,\n",
    "            'f1': f1,\n",
    "            'true_positives': true_positives,\n",
    "            'false_positives': false_positives,\n",
    "            'false_negatives': false_negatives\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5076f59a",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f590e98a",
   "metadata": {},
   "source": [
    "**DatabaseConnection and DBQueryExecutor Classes**\n",
    "\n",
    "These classes manage database connections and execute queries, providing a robust interface for database operations in Python.\n",
    "\n",
    "---\n",
    "\n",
    "**DatabaseConnection Class**\n",
    "\n",
    "The `DatabaseConnection` class handles establishing, maintaining, and closing connections to a PostgreSQL database.\n",
    "\n",
    "***Key Attributes:***\n",
    "1. `params`:\n",
    "   * Connection parameters, including database name, user, password, host, and port.\n",
    "2. `conn`:\n",
    "   * The active database connection object (`psycopg2.extensions.connection`).\n",
    "3. `cur`:\n",
    "   * The active database cursor object (`psycopg2.extensions.cursor`).\n",
    "4. `logger`:\n",
    "   * A logger to track connection events and errors.\n",
    "\n",
    "***Key Methods:***\n",
    "\n",
    "1. **`connect()`**:\n",
    "   * Establishes a connection to the database and initializes the cursor.\n",
    "   * Logs success or raises an error if the connection fails.\n",
    "\n",
    "2. **`disconnect()`**:\n",
    "   * Closes the active database connection and cursor.\n",
    "   * Logs success or raises an error if disconnection fails.\n",
    "\n",
    "3. **`__enter__()`**:\n",
    "   * Enables the class to be used as a context manager (`with` statement).\n",
    "   * Automatically calls `connect()` when entering the block.\n",
    "\n",
    "4. **`__exit__()`**:\n",
    "   * Automatically calls `disconnect()` when exiting a `with` block.\n",
    "\n",
    "---\n",
    "\n",
    "**DBQueryExecutor Class**\n",
    "\n",
    "The `DBQueryExecutor` class uses an instance of `DatabaseConnection` to execute SQL queries and retrieve results.\n",
    "\n",
    "***Key Attributes:***\n",
    "1. `db`:\n",
    "   * An instance of `DatabaseConnection` to manage the database connection lifecycle.\n",
    "2. `logger`:\n",
    "   * A logger to track query execution events and errors.\n",
    "\n",
    "***Key Methods:***\n",
    "\n",
    "1. **`execute_query(query: str, params: tuple = None) -> list`**:\n",
    "   * Executes a provided SQL query with optional parameters.\n",
    "   * **Steps**:\n",
    "       1. Uses the `DatabaseConnection` instance as a context manager to ensure the connection is properly opened and closed.\n",
    "       2. Executes the query and retrieves the results.\n",
    "   * **Returns:** A list of rows fetched from the database.\n",
    "   * Logs success or raises an error if query execution fails.\n",
    "\n",
    "---\n",
    "\n",
    "**Workflow Summary:**\n",
    "\n",
    "1. **DatabaseConnection**:\n",
    "   - Manages the lifecycle of a database connection.\n",
    "   - Allows the use of a `with` statement for clean and automatic resource management.\n",
    "\n",
    "2. **DBQueryExecutor**:\n",
    "   - Executes SQL queries using the database connection.\n",
    "   - Fetches and returns query results, ensuring robust error handling.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ce55dd3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "from psycopg2 import Error\n",
    "from typing import Optional\n",
    "import logging\n",
    "\n",
    "class DatabaseConnection:\n",
    "    def __init__(self, \n",
    "                 dbname: str = \"capstone_db\",\n",
    "                 user: str = \"postgres\",\n",
    "                 password: str = \"mysecretpassword\",\n",
    "                 host: str = \"localhost\",\n",
    "                 port: str = \"5432\"):\n",
    "        \"\"\"\n",
    "        Initialize database connection parameters.\n",
    "        \n",
    "        Args:\n",
    "            dbname: Database name\n",
    "            user: Database user\n",
    "            password: Database password\n",
    "            host: Database host\n",
    "            port: Database port\n",
    "        \"\"\"\n",
    "        self.params = {\n",
    "            \"dbname\": dbname,\n",
    "            \"user\": user,\n",
    "            \"password\": password,\n",
    "            \"host\": host,\n",
    "            \"port\": port\n",
    "        }\n",
    "        self.conn: Optional[psycopg2.extensions.connection] = None\n",
    "        self.cur: Optional[psycopg2.extensions.cursor] = None\n",
    "        self.logger = logging.getLogger(__name__)\n",
    "\n",
    "    def connect(self):\n",
    "        \"\"\"Establish database connection and create cursor.\"\"\"\n",
    "        try:\n",
    "            self.conn = psycopg2.connect(**self.params)\n",
    "            self.cur = self.conn.cursor()\n",
    "            self.logger.info(\"Database connection established successfully\")\n",
    "        except Error as e:\n",
    "            self.logger.error(f\"Error connecting to database: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "    def disconnect(self):\n",
    "        \"\"\"Close database connection and cursor.\"\"\"\n",
    "        try:\n",
    "            if self.cur:\n",
    "                self.cur.close()\n",
    "            if self.conn:\n",
    "                self.conn.close()\n",
    "            self.logger.info(\"Database connection closed successfully\")\n",
    "        except Error as e:\n",
    "            self.logger.error(f\"Error closing database connection: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "    def __enter__(self):\n",
    "        \"\"\"Context manager entry point.\"\"\"\n",
    "        self.connect()\n",
    "        return self.conn\n",
    "\n",
    "    def __exit__(self, exc_type, exc_val, exc_tb):\n",
    "        \"\"\"Context manager exit point.\"\"\"\n",
    "        self.disconnect()\n",
    "        \n",
    "class DBQueryExecutor:\n",
    "    def __init__(self, db_connection: DatabaseConnection):\n",
    "        \"\"\"\n",
    "        Initialize query executor with database connection.\n",
    "        \n",
    "        Args:\n",
    "            db_connection: DatabaseConnection instance\n",
    "        \"\"\"\n",
    "        self.db = db_connection\n",
    "        self.logger = logging.getLogger(__name__)\n",
    "\n",
    "    def execute_query(self, query: str, params: tuple = None) -> list:\n",
    "        \"\"\"\n",
    "        Execute a query and return results.\n",
    "        \n",
    "        Args:\n",
    "            query: SQL query string\n",
    "            params: Query parameters\n",
    "            \n",
    "        Returns:\n",
    "            List of query results\n",
    "        \"\"\"\n",
    "        try:\n",
    "            with self.db as conn:\n",
    "                with conn.cursor() as cur:\n",
    "                    cur.execute(query, params)\n",
    "                    return cur.fetchall()\n",
    "        except Error as e:\n",
    "            self.logger.error(f\"Error executing query: {str(e)}\")\n",
    "            raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f99da75",
   "metadata": {},
   "source": [
    "**Here I'm initilizing the database connection. For reproducibility make sure you provide the appropriate database configurations**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2b82f509-dba5-4571-8d4e-d63d1a7e5fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize database connection\n",
    "db = DatabaseConnection(\n",
    "    dbname=\"capstone_db\",\n",
    "    user=\"postgres\",\n",
    "    password=\"mysecretpassword\",\n",
    "    host=\"localhost\",\n",
    "    port=\"5432\"\n",
    ")\n",
    "query_executor = DBQueryExecutor(db)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96b7fc81",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d9c74b29",
   "metadata": {},
   "source": [
    "### **Code Explanation: Initializing and Using NLIProcessor and StandardsComparator**\n",
    "\n",
    "This snippet demonstrates how to initialize the necessary components and retrieve domains for specific grades using the `StandardsComparator`.\n",
    "\n",
    "---\n",
    "\n",
    "#### **Key Components:**\n",
    "\n",
    "1. **`nli_processor`**:\n",
    "   * An instance of the `NLIProcessor` class.\n",
    "   * Responsible for evaluating semantic relationships between concepts, clusters, and standards using Natural Language Inference (NLI).\n",
    "\n",
    "2. **`standards_comparator`**:\n",
    "   * An instance of the `StandardsComparator` class.\n",
    "   * Combines NLI capabilities (`nli_processor`) with database querying (`query_executor`).\n",
    "   * Facilitates mapping concepts to standards and clusters while supporting grade-specific filtering.\n",
    "\n",
    "3. **`domains_to_be_checked`**:\n",
    "   * A list to store domains retrieved for grades 6 through 12.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecc395ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Loading NLI model: ynie/xlnet-large-cased-snli_mnli_fever_anli_R1_R2_R3-nli\n",
      "INFO:__main__:Database connection established successfully\n",
      "INFO:__main__:Database connection closed successfully\n",
      "INFO:__main__:Database connection established successfully\n",
      "INFO:__main__:Database connection closed successfully\n",
      "INFO:__main__:Database connection established successfully\n",
      "INFO:__main__:Database connection closed successfully\n",
      "INFO:__main__:Database connection established successfully\n",
      "INFO:__main__:Database connection closed successfully\n",
      "INFO:__main__:Database connection established successfully\n",
      "INFO:__main__:Database connection closed successfully\n",
      "INFO:__main__:Database connection established successfully\n",
      "INFO:__main__:Database connection closed successfully\n",
      "INFO:__main__:Database connection established successfully\n",
      "INFO:__main__:Database connection closed successfully\n"
     ]
    }
   ],
   "source": [
    "nli_processor = NLIProcessor()\n",
    "\n",
    "standards_comparator = StandardsComparator(nli_processor, query_executor)\n",
    "\n",
    "\n",
    "domains_to_be_checked = []\n",
    "for grade_id in range(6,13):\n",
    "    domains = standards_comparator.get_domains_for_grade(grade_id)\n",
    "    domains_to_be_checked.append(domains)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8697d1f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7b9613cf",
   "metadata": {},
   "source": [
    "### **Code Explanation: Retrieving Clusters for Domains**\n",
    "\n",
    "This snippet retrieves clusters for all domains across grades 6 to 12 and stores them.\n",
    "\n",
    "---\n",
    "\n",
    "1. **Input:**\n",
    "   - `domains_to_be_checked`: A list of domains grouped by grade (from previous processing).\n",
    "\n",
    "2. **Process:**\n",
    "   - Iterates through each grade's domains.\n",
    "   - For each domain, calls `get_clusters_for_domain` to fetch associated clusters from the database.\n",
    "\n",
    "3. **Output:**\n",
    "   - `cluster_matches`: A list containing clusters for all domains, grouped by grade.\n",
    "\n",
    "---\n",
    "\n",
    "**Result:**  \n",
    "Clusters are now retrieved and organized for further analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1348a681",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_matches = []\n",
    "for grade_domains in domains_to_be_checked:\n",
    "    for domains in grade_domains:\n",
    "\n",
    "        clusters = standards_comparator.get_clusters_for_domain(domains.domainid)\n",
    "\n",
    "        cluster_matches.append(clusters)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff745e01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "16913875",
   "metadata": {},
   "source": [
    "### **Workflow: Using DataProcessor and ConceptAnalyzer**\n",
    "\n",
    "The following demonstrates how to initialize and use the `DataProcessor` and `ConceptAnalyzer` classes to process educational materials using chapter files store in the Data file which I already define in the DataProcessor Class.\n",
    "\n",
    "---\n",
    "\n",
    "**Steps:**\n",
    "\n",
    "1. **Initialize the Classes**:\n",
    "   * `DataProcessor` is used to manage and validate PDF files (e.g., chapters).\n",
    "   * `ConceptAnalyzer` extracts key concepts from the files using OpenAI’s language models.\n",
    "   ```python\n",
    "   processor = DataProcessor()\n",
    "   analyzer = ConceptAnalyzer(openai_api_key=os.getenv('OPENAI_API_KEY'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48eef1aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Starting analysis for document: test_file.pdf\n",
      "INFO:__main__:Converting Chapter 1: test_file.pdf\n",
      "INFO:__main__:Processed page 1/12 of Chapter 1\n",
      "INFO:__main__:Processed page 2/12 of Chapter 1\n",
      "INFO:__main__:Processed page 3/12 of Chapter 1\n",
      "INFO:__main__:Processed page 4/12 of Chapter 1\n",
      "INFO:__main__:Processed page 5/12 of Chapter 1\n",
      "INFO:__main__:Processed page 6/12 of Chapter 1\n",
      "INFO:__main__:Processed page 7/12 of Chapter 1\n",
      "INFO:__main__:Processed page 8/12 of Chapter 1\n",
      "INFO:__main__:Processed page 9/12 of Chapter 1\n",
      "INFO:__main__:Processed page 10/12 of Chapter 1\n",
      "INFO:__main__:Processed page 11/12 of Chapter 1\n",
      "INFO:__main__:Processed page 12/12 of Chapter 1\n",
      "INFO:__main__:Completed processing for Chapter 1\n",
      "INFO:__main__:Converting Chapter 2: test_file.pdf\n",
      "INFO:__main__:Processed page 1/15 of Chapter 2\n",
      "INFO:__main__:Processed page 2/15 of Chapter 2\n",
      "INFO:__main__:Processed page 3/15 of Chapter 2\n",
      "INFO:__main__:Processed page 4/15 of Chapter 2\n",
      "INFO:__main__:Processed page 5/15 of Chapter 2\n",
      "INFO:__main__:Processed page 6/15 of Chapter 2\n",
      "INFO:__main__:Processed page 7/15 of Chapter 2\n",
      "INFO:__main__:Processed page 8/15 of Chapter 2\n",
      "INFO:__main__:Processed page 9/15 of Chapter 2\n",
      "INFO:__main__:Processed page 10/15 of Chapter 2\n",
      "INFO:__main__:Processed page 11/15 of Chapter 2\n",
      "INFO:__main__:Processed page 12/15 of Chapter 2\n",
      "INFO:__main__:Processed page 13/15 of Chapter 2\n",
      "INFO:__main__:Processed page 14/15 of Chapter 2\n",
      "INFO:__main__:Processed page 15/15 of Chapter 2\n",
      "INFO:__main__:Completed processing for Chapter 2\n",
      "INFO:__main__:Converting Chapter 3: test_file.pdf\n",
      "INFO:__main__:Processed page 1/20 of Chapter 3\n",
      "INFO:__main__:Processed page 2/20 of Chapter 3\n",
      "INFO:__main__:Processed page 3/20 of Chapter 3\n",
      "INFO:__main__:Processed page 4/20 of Chapter 3\n",
      "INFO:__main__:Processed page 5/20 of Chapter 3\n",
      "INFO:__main__:Processed page 6/20 of Chapter 3\n",
      "INFO:__main__:Processed page 7/20 of Chapter 3\n",
      "INFO:__main__:Processed page 8/20 of Chapter 3\n",
      "INFO:__main__:Processed page 9/20 of Chapter 3\n",
      "INFO:__main__:Processed page 10/20 of Chapter 3\n",
      "INFO:__main__:Processed page 11/20 of Chapter 3\n",
      "INFO:__main__:Processed page 12/20 of Chapter 3\n",
      "INFO:__main__:Processed page 13/20 of Chapter 3\n",
      "INFO:__main__:Processed page 14/20 of Chapter 3\n",
      "INFO:__main__:Processed page 15/20 of Chapter 3\n",
      "INFO:__main__:Processed page 16/20 of Chapter 3\n",
      "INFO:__main__:Processed page 17/20 of Chapter 3\n",
      "INFO:__main__:Processed page 18/20 of Chapter 3\n",
      "INFO:__main__:Processed page 19/20 of Chapter 3\n",
      "INFO:__main__:Processed page 20/20 of Chapter 3\n",
      "INFO:__main__:Completed processing for Chapter 3\n",
      "INFO:__main__:Converting Chapter 4: test_file.pdf\n",
      "INFO:__main__:Processed page 1/18 of Chapter 4\n",
      "INFO:__main__:Processed page 2/18 of Chapter 4\n",
      "INFO:__main__:Processed page 3/18 of Chapter 4\n",
      "INFO:__main__:Processed page 4/18 of Chapter 4\n",
      "INFO:__main__:Processed page 5/18 of Chapter 4\n",
      "INFO:__main__:Processed page 6/18 of Chapter 4\n",
      "INFO:__main__:Processed page 7/18 of Chapter 4\n",
      "INFO:__main__:Processed page 8/18 of Chapter 4\n",
      "INFO:__main__:Processed page 9/18 of Chapter 4\n",
      "INFO:__main__:Processed page 10/18 of Chapter 4\n",
      "INFO:__main__:Processed page 11/18 of Chapter 4\n",
      "INFO:__main__:Processed page 12/18 of Chapter 4\n",
      "INFO:__main__:Processed page 13/18 of Chapter 4\n",
      "INFO:__main__:Processed page 14/18 of Chapter 4\n",
      "INFO:__main__:Processed page 15/18 of Chapter 4\n",
      "INFO:__main__:Processed page 16/18 of Chapter 4\n",
      "INFO:__main__:Processed page 17/18 of Chapter 4\n",
      "INFO:__main__:Processed page 18/18 of Chapter 4\n",
      "INFO:__main__:Completed processing for Chapter 4\n",
      "INFO:__main__:Converting Chapter 5: test_file.pdf\n",
      "INFO:__main__:Processed page 1/14 of Chapter 5\n",
      "INFO:__main__:Processed page 2/14 of Chapter 5\n",
      "INFO:__main__:Processed page 3/14 of Chapter 5\n",
      "INFO:__main__:Processed page 4/14 of Chapter 5\n",
      "INFO:__main__:Processed page 5/14 of Chapter 5\n",
      "INFO:__main__:Processed page 6/14 of Chapter 5\n",
      "INFO:__main__:Processed page 7/14 of Chapter 5\n",
      "INFO:__main__:Processed page 8/14 of Chapter 5\n",
      "INFO:__main__:Processed page 9/14 of Chapter 5\n",
      "INFO:__main__:Processed page 10/14 of Chapter 5\n",
      "INFO:__main__:Processed page 11/14 of Chapter 5\n",
      "INFO:__main__:Processed page 12/14 of Chapter 5\n",
      "INFO:__main__:Processed page 13/14 of Chapter 5\n",
      "INFO:__main__:Processed page 14/14 of Chapter 5\n",
      "INFO:__main__:Completed processing for Chapter 5\n",
      "INFO:__main__:Converting Chapter 6: test_file.pdf\n",
      "INFO:__main__:Processed page 1/22 of Chapter 6\n",
      "INFO:__main__:Processed page 2/22 of Chapter 6\n",
      "INFO:__main__:Processed page 3/22 of Chapter 6\n",
      "INFO:__main__:Processed page 4/22 of Chapter 6\n",
      "INFO:__main__:Processed page 5/22 of Chapter 6\n",
      "INFO:__main__:Processed page 6/22 of Chapter 6\n",
      "INFO:__main__:Processed page 7/22 of Chapter 6\n",
      "INFO:__main__:Processed page 8/22 of Chapter 6\n",
      "INFO:__main__:Processed page 9/22 of Chapter 6\n",
      "INFO:__main__:Processed page 10/22 of Chapter 6\n",
      "INFO:__main__:Processed page 11/22 of Chapter 6\n",
      "INFO:__main__:Processed page 12/22 of Chapter 6\n",
      "INFO:__main__:Processed page 13/22 of Chapter 6\n",
      "INFO:__main__:Processed page 14/22 of Chapter 6\n",
      "INFO:__main__:Processed page 15/22 of Chapter 6\n",
      "INFO:__main__:Processed page 16/22 of Chapter 6\n",
      "INFO:__main__:Processed page 17/22 of Chapter 6\n",
      "INFO:__main__:Processed page 18/22 of Chapter 6\n",
      "INFO:__main__:Processed page 19/22 of Chapter 6\n",
      "INFO:__main__:Processed page 20/22 of Chapter 6\n",
      "INFO:__main__:Processed page 21/22 of Chapter 6\n",
      "INFO:__main__:Processed page 22/22 of Chapter 6\n",
      "INFO:__main__:Completed processing for Chapter 6\n",
      "INFO:__main__:Converting Chapter 7: test_file.pdf\n",
      "INFO:__main__:Processed page 1/11 of Chapter 7\n",
      "INFO:__main__:Processed page 2/11 of Chapter 7\n",
      "INFO:__main__:Processed page 3/11 of Chapter 7\n",
      "INFO:__main__:Processed page 4/11 of Chapter 7\n",
      "INFO:__main__:Processed page 5/11 of Chapter 7\n",
      "INFO:__main__:Processed page 6/11 of Chapter 7\n",
      "INFO:__main__:Processed page 7/11 of Chapter 7\n",
      "INFO:__main__:Processed page 8/11 of Chapter 7\n",
      "INFO:__main__:Processed page 9/11 of Chapter 7\n",
      "INFO:__main__:Processed page 10/11 of Chapter 7\n",
      "INFO:__main__:Processed page 11/11 of Chapter 7\n",
      "INFO:__main__:Completed processing for Chapter 7\n",
      "INFO:__main__:HTTP Request: POST https://api.openai.com/v1/chat/completions 'HTTP/1.1 200 OK'\n",
      "INFO:__main__:Analysis completed and saved to: Data/results/test_file.pdf_concepts.json\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Initialize both classes\n",
    "processor = DataProcessor()\n",
    "concept_analyzer = ConceptAnalyzer(openai_api_key=os.getenv('OPENAI_API_KEY'))\n",
    "\n",
    "# Process test file\n",
    "test_file = processor.get_chapter_files()\n",
    "concepts = analyzer.analyze_document(str(chapter_files))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42e28171",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4869cd02",
   "metadata": {},
   "source": [
    "### **Code Explanation: Matching Concepts to Clusters**\n",
    "\n",
    "This snippet matches extracted concepts to clusters using the `StandardsComparator`.\n",
    "\n",
    "---\n",
    "\n",
    "1. **Input:**\n",
    "   - `concepts['concepts']`: A list of extracted concepts.\n",
    "   - `cluster_matches`: Clusters retrieved for all domains.\n",
    "\n",
    "2. **Process:**\n",
    "   - Iterates through each set of clusters.\n",
    "   - Calls `match_concepts_to_clusters` to compare concepts with clusters using NLI.\n",
    "   - Appends the matches to `cluster_matches_collector`.\n",
    "\n",
    "3. **Output:**\n",
    "   - `cluster_matches_collector`: A list of concept-to-cluster matches, grouped by the original clusters.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d6219253",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_matches_collector = []\n",
    "for clusters in cluster_matches:\n",
    "    \n",
    "    cluster_matches = standards_comparator.match_concepts_to_clusters(concepts['concepts'], clusters)\n",
    "    cluster_matches_collector.append(cluster_matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d35d3842",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bd763979",
   "metadata": {},
   "source": [
    "### **Code Explanation: Matching Concepts to Standards**\n",
    "\n",
    "This snippet refines the matching process by linking concepts to relevant standards within clusters.\n",
    "\n",
    "---\n",
    "\n",
    "1. **Input:**\n",
    "   - `cluster_matches_collector[0]`: The first element of cluster_matches_collector is the retrived clusters, hence cluster_matches_collector[0].\n",
    "   - `standards`: Standards retrieved for each cluster.\n",
    "\n",
    "2. **Process:**\n",
    "   - Iterates through the matched concepts and clusters.\n",
    "   - Retrieves standards for each cluster using `get_standards_for_cluster`.\n",
    "   - Matches the concept to the standards using `match_concepts_to_standards`.\n",
    "   - Appends the matches to `all_standard_matches`.\n",
    "\n",
    "3. **Output:**\n",
    "   - `all_standard_matches`: A comprehensive list of concept-to-standard matches.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a7a06433",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Database connection established successfully\n",
      "INFO:__main__:Database connection closed successfully\n"
     ]
    }
   ],
   "source": [
    "all_standard_matches = []\n",
    "for concept, cluster, score in cluster_matches_collector[0]:\n",
    "    standards = standards_comparator.get_standards_for_cluster(cluster.clusterid)\n",
    "    standard_matches = standards_comparator.match_concepts_to_standards([concept], standards)\n",
    "    all_standard_matches.extend(standard_matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21901906",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7644677b",
   "metadata": {},
   "source": [
    "### **Code Explanation: Evaluating Concept-to-Standard Matches**\n",
    "\n",
    "This snippet evaluates the performance of the matching process by comparing the predicted matches against the ground truth standards.\n",
    "\n",
    "---\n",
    "\n",
    "1. **Input:**\n",
    "   - `ground_truth_standards`: A list of correct standard codes ( from aformentione annotated textbook).\n",
    "   - `all_standard_matches`: Predicted matches between concepts and standards.\n",
    "\n",
    "2. **Process:**\n",
    "   - Calls `compare_to_ground_truth` to calculate evaluation metrics:\n",
    "     - **Precision**: Proportion of correctly matched standards out of all predicted matches.\n",
    "     - **Recall**: Proportion of ground truth standards correctly identified.\n",
    "     - **F1 Score**: Harmonic mean of precision and recall.\n",
    "   - Metrics are stored in the `metrics` dictionary.\n",
    "\n",
    "3. **Output:**\n",
    "   - Prints evaluation metrics (precision, recall, F1 score).\n",
    "\n",
    "---\n",
    "\n",
    "**Result:**\n",
    "Performance metrics provide insight into the accuracy and relevance of the concept-to-standard matching process, enabling further optimization or validation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8076fa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Metrics:\n",
      "Recall: 0.89\n",
      "Precision: 0.73\n",
      "F1 Score: 0.80\n"
     ]
    }
   ],
   "source": [
    "ground_truth_standards = [\n",
    "    \"6.EE.A.2\",\n",
    "    \"6.EE.A.2\",\n",
    "    \"6.EE.B.6\",\n",
    "    \"6.EE.B.8\",\n",
    "    \"6.EE.C.9\",\n",
    "    \"6.EE.A.1\",\n",
    "    \"HS.N-RN.A.1\",\n",
    "    \"8.EE.A.1\",\n",
    "    \"8.EE.A.2\",\n",
    "    \"6.EE.A.2\",\n",
    "    \"6.EE.A.2\",\n",
    "    \"6.EE.A.4\",\n",
    "    \"HS.A-SSE.A.1\",\n",
    "    \"7.EE.A.1\",\n",
    "    \"7.EE.A.2\",\n",
    "    \"7.EE.B.3\",\n",
    "    \"6.EE.B.5\",\n",
    "    \"7.EE.B.4\",\n",
    "    \"HS.F-IF.A.1\",\n",
    "    \"HS.F-IF.A.2\",\n",
    "    \"HS.F-IF.B.4\",\n",
    "    \"HS.F-IF.C.8\",\n",
    "    \"HS.F-BF.A.1\",\n",
    "    \"HS.F-BF.A.1\",\n",
    "    \"HS.F-BF.A.1\",\n",
    "    \"8.F.A.1\",\n",
    "    \"HS.F-IF.C.9\",\n",
    "    \"HS.A-REI.D.10\",\n",
    "    \"HS.F-IF.C.7\",\n",
    "    \"HS.F-IF.C.7\",\n",
    "    \"8.EE.B.5\",\n",
    "    \"HS.F-LE.A.3\",\n",
    "    \"HS.F-LE.A.2\",\n",
    "    \"6.SP.B.5.A\",\n",
    "    \"HS.A-CED.A.1\",\n",
    "    \"6.SP.B.5.B\"\n",
    "]\n",
    "\n",
    "metrics = standards_comparator.compare_to_ground_truth(all_standard_matches, ground_truth_standards)\n",
    "\n",
    "print(\"Evaluation Metrics:\")\n",
    "print(f\"Precision: {metrics['precision']:.2f}\")\n",
    "print(f\"Recall: {metrics['recall']:.2f}\")\n",
    "print(f\"F1 Score: {metrics['f1']:.2f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4839a4ce",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
